{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using dask for large systems of financial models\n",
    "## Basic Example\n",
    "\n",
    "Petr Wolf, Dhivya Shankaranarayan\n",
    "\n",
    "This notebook illustrates the concepts presented in \"[Using dask for large systems of financial models](https://pydata.org/nyc2018/schedule/presentation/16/)\" talk from [PyData NYC 2018](https://pydata.org/nyc2018).\n",
    "\n",
    "Source location:\n",
    "* [Notebook](https://github.com/PetrWolf/pydata_nyc_2018)\n",
    "* [Slides](https://www.slideshare.net/PetrWolf1/using-dask-for-large-systems-of-financial-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To run this notebook, you need Python 3.6, IPython, cytoolz dask and graphviz.\n",
    "\n",
    "Use conda to install them all:\n",
    "\n",
    "```\n",
    "conda env create -p <target/env/location> --file example.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "Note that this notebook serves only as an example to demonstrate the main idea of the presentation. \n",
    "\n",
    "Many details needed for a real implementation (e.g. checks, validation, multiple outputs) are deliberately not covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from cytoolz import dicttoolz\n",
    "from IPython.display import display\n",
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions\n",
    "Definition of a @model decorator as a syntax extension for easier development and maintenance.\n",
    "\n",
    "This decorator lets model developers annotate their functions with references to a global catalogue of all data, so that\n",
    "automatic connections between models can be established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(output, **inputs):\n",
    "    \"\"\"Decorator for annotating functions with input and output data labels.\n",
    "    \n",
    "    It wraps the underlying function and adds the following properties to the wrapper object:\n",
    "        dsk - a dask graph representing the function's dependencies\n",
    "        _repr_csv_ - to support visualization in Jupyter\n",
    "    \n",
    "    Args:\n",
    "        inputs: data labels for input arguments\n",
    "        output: data label for return value    \n",
    "    \"\"\"\n",
    "    def model_decorator(f):\n",
    "        @functools.wraps(f)\n",
    "        def wrapper(*args, **kwds):\n",
    "            return f(*args, **kwds)\n",
    "        \n",
    "        # Define the dask graph using Dask Custom Graph API notation.\n",
    "        # Use None as the value of input nodes (so that they can be used in connections later)\n",
    "        #\n",
    "        # See Also\n",
    "        # * http://docs.dask.org/en/latest/custom-graphs.html\n",
    "        dsk = {\n",
    "            output: (f, ) + tuple(inputs.values())\n",
    "        }\n",
    "        dsk.update({\n",
    "            key: None for key in inputs.values()\n",
    "        })\n",
    "        wrapper.dsk = dsk\n",
    "        \n",
    "        # Add _repr_svg_ for visualization in Jupyter\n",
    "        #\n",
    "        # See Also:\n",
    "        # * http://docs.dask.org/en/latest/graphviz.html\n",
    "        # * https://ipython.readthedocs.io/en/stable/config/integrating.html\n",
    "        wrapper._repr_svg_ = lambda : display(dask.visualize(dsk, rankdir='LR'))\n",
    "        return wrapper\n",
    "    \n",
    "    return model_decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use `@model` in a simple example.\n",
    "\n",
    "Both 'FOO' and 'BAR' are assummed to be globally defined data labels with a well-defined meaning, type and unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model(foo='FOO', output='BAR')\n",
    "def my_model(foo):\n",
    "    \"\"\"A sample model.\n",
    "    Computes the value of 'FOO' based on 'BAR'.\n",
    "    \n",
    "    Args:\n",
    "        foo: value of 'FOO'\n",
    "    \n",
    "    Returns:\n",
    "        value of 'BAR'\n",
    "    \"\"\"\n",
    "    return foo + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the dask graph corresponding to this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.dsk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging graphs\n",
    "\n",
    "The above concept becomes useful when merging multiple functions together into larger dependency graphs or evolving components within existing graphs.\n",
    "\n",
    "To this end, we define a `join_graphs` function for merging two dask graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_graphs(a, b):\n",
    "    \"\"\"Operation to join two dask graphs.\n",
    "    Where an output of one graphs matches an input to the other, a connection is created.\n",
    "    If both graphs declare the same output, an exception is raised.\n",
    "    \n",
    "    Args:\n",
    "        a, b: dask graphs to join\n",
    "    \n",
    "    Returns:\n",
    "        new dask graph, created from `a` and `b`\n",
    "    \n",
    "    Raises:\n",
    "        RuntimeError: if both graph define the same output\n",
    "    \"\"\"    \n",
    "    return dicttoolz.merge_with(merge_dask_values, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dask_values(outputs):\n",
    "    \"\"\"Perform a merge of dask graph values\"\"\"\n",
    "    producers = list(filter(None, outputs))\n",
    "    if len(producers) == 0:\n",
    "        return None\n",
    "    elif len(producers) == 1:\n",
    "        return producers[0] \n",
    "    else:\n",
    "        raise RuntimeError('Conflict among producers') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add a second function, consuming 'BAR' and computing 'BAZ' from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model(bar='BAR', output='BAZ')\n",
    "def another_model(bar):\n",
    "    \"\"\"Another sample model\n",
    "    \n",
    "    Args:\n",
    "        bar: value of 'BAR'\n",
    "        \n",
    "    Returns:\n",
    "        value of 'BAZ'\n",
    "    \"\"\"\n",
    "    return bar * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By joining the two, we get a dask graph with three keys, one of which is an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_graphs(my_model.dsk, another_model.dsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(join_graphs(my_model.dsk, another_model.dsk), rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data\n",
    "So far, the graph is entirely \"abstract\" and does not contain any actual values.\n",
    "In order to use it for a computation, we must \"initialize\" the input nodes with actual values from a given context.\n",
    "\n",
    "To that end, we add the concept of a \"loader\" function,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loader(dsk, loader):\n",
    "    \"\"\"Connects a loader function call to each input node in the graph.\n",
    "    \n",
    "    A `loader` is a callable taking a data label and returning its value.\n",
    "    \n",
    "    Args:\n",
    "        dsk: a dsk graph, where input nodes have value None\n",
    "        loader: a function responsible for loading and returning a value for a given key\n",
    "    \n",
    "    Returns:\n",
    "        a new dask graph with all \"free\" inputs connected to the loader function\n",
    "    \"\"\"\n",
    "    return {key: value if value else (functools.partial(loader, key), ) \n",
    "            for key,value in dsk.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loader(key):\n",
    "    \"\"\"Sample loader function.\n",
    "    \n",
    "    In this example, we only expect to load the value of foo.\n",
    "    A \"real\" loader might read files, access a database or a service to retrieve the value of a given key\n",
    "    \"\"\"\n",
    "    assert key == 'FOO' \n",
    "    return 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_graph = add_loader(join_graphs(my_model.dsk, another_model.dsk), my_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(final_graph, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "When a graph has no \"free\" input nodes, it can be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.get(final_graph, 'BAZ')  # expecting (42 + 1) * 2 = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Clearly, such a trivial example hardly requires automated graph creation.\n",
    "But the same principle can easily scale up to graphs of 100s or 1000s of functions, developed and tested individually and independently, while leveraging all the parallel execution and caching goodness of `dask`.\n",
    "\n",
    "Example graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](dot-1024.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
